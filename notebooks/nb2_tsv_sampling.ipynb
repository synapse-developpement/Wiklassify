{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from colorama import init, Fore, Back, Style\n",
    "from time import time, gmtime, strftime\n",
    "from datetime import datetime\n",
    "from hyperdash import monitor_cell  \n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize as tokenizer\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell # no need of print for several objects!!!\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over XML files for random draw of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tsv_list = [\"00-meta-history1.xml-p3p3661.tsv\",\"01-meta-history1.xml-p3662p10075.tsv\",\"02-meta-history1.xml-p10076p18526.tsv\",\"03-meta-history1.xml-p18527p30361.tsv\",\"04-meta-history1.xml-p30362p43904.tsv\",\"05-meta-history1.xml-p43905p56252.tsv\",\"06-meta-history1.xml-p56253p71552.tsv\",\"07-meta-history1.xml-p71553p89754.tsv\",\"08-meta-history1.xml-p89755p107570.tsv\",\"09-meta-history1.xml-p107571p128187.tsv\",\n",
    "\"10-meta-history1.xml-p128188p150477.tsv\",\"11-meta-history1.xml-p150478p174227.tsv\",\"12-meta-history1.xml-p174228p196344.tsv\",\"13-meta-history1.xml-p196345p222500.tsv\",\"14-meta-history1.xml-p222501p250312.tsv\",\"15-meta-history1.xml-p250313p280868.tsv\",\"16-meta-history1.xml-p280869p307896.tsv\",\"17-meta-history1.xml-p307897p329059.tsv\",\"18-meta-history1.xml-p329060p356265.tsv\",\"19-meta-history1.xml-p356266p389955.tsv\",\n",
    "\"20-meta-history1.xml-p389956p412301.tsv\",\"21-meta-history2.xml-p412304p449997.tsv\",\"22-meta-history2.xml-p449998p485915.tsv\",\"23-meta-history2.xml-p485916p527163.tsv\",\"24-meta-history2.xml-p527164p564312.tsv\",\"25-meta-history2.xml-p564313p612957.tsv\",\"26-meta-history2.xml-p612958p662695.tsv\",\"27-meta-history2.xml-p662696p715915.tsv\",\"28-meta-history2.xml-p715916p770350.tsv\",\"29-meta-history2.xml-p770351p824123.tsv\",\n",
    "\"30-meta-history2.xml-p824124p876600.tsv\",\"31-meta-history2.xml-p876601p926793.tsv\",\"32-meta-history2.xml-p926794p985318.tsv\",\"33-meta-history2.xml-p985319p1045696.tsv\",\"34-meta-history2.xml-p1045697p1113860.tsv\",\"35-meta-history2.xml-p1113861p1186656.tsv\",\"36-meta-history2.xml-p1186657p1252585.tsv\",\"37-meta-history2.xml-p1252586p1312869.tsv\",\"38-meta-history2.xml-p1312870p1382438.tsv\",\"39-meta-history2.xml-p1382439p1454699.tsv\",\n",
    "\"40-meta-history2.xml-p1454700p1557686.tsv\",\"41-meta-history2.xml-p1557687p1647888.tsv\",\"42-meta-history3.xml-p1647895p1740137.tsv\",\"43-meta-history3.xml-p1740138p1843398.tsv\",\"44-meta-history3.xml-p1843399p1939691.tsv\",\"45-meta-history3.xml-p1939692p2031436.tsv\",\"46-meta-history3.xml-p2031437p2286439.tsv\",\"47-meta-history3.xml-p2286440p2501692.tsv\",\"48-meta-history3.xml-p2501693p2730817.tsv\",\"49-meta-history3.xml-p2730818p2832611.tsv\",\n",
    "\"50-meta-history3.xml-p2832612p2941309.tsv\",\"51-meta-history3.xml-p2941310p3055771.tsv\",\"52-meta-history3.xml-p3055772p3166492.tsv\",\"53-meta-history3.xml-p3166493p3305127.tsv\",\"54-meta-history3.xml-p3305128p3438516.tsv\",\"55-meta-history3.xml-p3438517p3561507.tsv\",\"56-meta-history3.xml-p3561508p3682191.tsv\",\"57-meta-history3.xml-p3682192p3796516.tsv\",\"58-meta-history3.xml-p3796517p3922524.tsv\",\"59-meta-history3.xml-p3922525p4040465.tsv\",\n",
    "\"60-meta-history3.xml-p4040466p4166564.tsv\",\"61-meta-history3.xml-p4166565p4310744.tsv\",\"62-meta-history3.xml-p4310745p4419858.tsv\",\"63-meta-history4.xml-p4419861p4565226.tsv\",\"64-meta-history4.xml-p4565227p4699279.tsv\",\"65-meta-history4.xml-p4699280p4830738.tsv\",\"66-meta-history4.xml-p4830739p4970702.tsv\",\"69-meta-history4.xml-p5314076p5483062.tsv\",\n",
    "\"70-meta-history4.xml-p5483063p5659533.tsv\",\"71-meta-history4.xml-p5659534p5847437.tsv\",\"72-meta-history4.xml-p5847438p6039053.tsv\"]\n",
    "\n",
    "len(full_tsv_list)\n",
    "\n",
    "#'64-meta-history4.xml-p4565227p4699279.tsv' is not processable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define input files set (eg: the 5 first elements of full_tsv_list)\n",
    "# one can also iterate over groups of 5 files\n",
    "\n",
    "list_files = full_tsv_list[0:5]\n",
    "\n",
    "# number of sample edits to be drawn from each tsv file\n",
    "n_user = 20\n",
    "\n",
    "# seed for random sampling, set None for undefined seed\n",
    "random_nbr = 73\n",
    "\n",
    "# if list_files containes 5 elements and n_user is 20,\n",
    "# df_sample will contain 5*20 = 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_sample deleted\n",
      "No df_full\n",
      "Total number of files: 5\n",
      "\n",
      "\n",
      "Processing input file: 35-meta-history2.xml-p1113861p1186656.tsv\n",
      "Running...\n",
      "Shape before filtering: 1,499,689 | 34\n",
      "Shape after filtering: 112,736 | 34\n",
      "Round runtime: 1:12\n",
      "\n",
      "\n",
      "Processing input file: 36-meta-history2.xml-p1186657p1252585.tsv\n",
      "Running...\n",
      "Shape before filtering: 1,498,372 | 34\n",
      "Shape after filtering: 116,564 | 34\n",
      "Round runtime: 1:05\n",
      "\n",
      "\n",
      "Processing input file: 37-meta-history2.xml-p1252586p1312869.tsv\n",
      "Running...\n",
      "Shape before filtering: 1,499,250 | 34\n",
      "Shape after filtering: 101,767 | 34\n",
      "Round runtime: 1:05\n",
      "\n",
      "\n",
      "Processing input file: 38-meta-history2.xml-p1312870p1382438.tsv\n",
      "Running...\n",
      "Shape before filtering: 1,497,167 | 34\n",
      "Shape after filtering: 112,565 | 34\n",
      "Round runtime: 1:10\n",
      "\n",
      "\n",
      "Processing input file: 39-meta-history2.xml-p1382439p1454699.tsv\n",
      "Running...\n",
      "Shape before filtering: 1,499,709 | 34\n",
      "Shape after filtering: 94,256 | 34\n",
      "Round runtime: 1:15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 34)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Running time: 0:05:50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "\n",
    "path = '/media/hdd/salaun/wikiedit/tsv_output/' # path of tsv files\n",
    "\n",
    "try:\n",
    "    del df_sample\n",
    "    print('df_sample deleted')\n",
    "except:\n",
    "    print('No df_sample')\n",
    "try:\n",
    "    del df_full\n",
    "    print('df_full deleted')\n",
    "except:\n",
    "    print('No df_full')\n",
    "\n",
    "print(\"Total number of files to be processed:\", len(list_files))\n",
    "\n",
    "init = True # initialize\n",
    "\n",
    "for file in list_files:\n",
    "    \n",
    "    t1 = time()\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Processing input file:', file)\n",
    "    print('Running...')\n",
    "    df_full = pd.read_csv(path+file, sep ='\\t')\n",
    "    \n",
    "    ##### START FILTERS\n",
    "    print('Shape before filtering: {0:,} rows | {1:,} columns'.format(df_full.shape[0], df_full.shape[1]))\n",
    "    \n",
    "    # remove version pairs with empty strings\n",
    "    df_full = df_full.fillna('')\n",
    "    df_full = df_full[(df_full.modif_remove != \"\") & (df_full.modif_add != \"\")]\n",
    "    for element in [' ', '\\n']:\n",
    "        df_full = df_full[~df_full.modif_remove.str.startswith(element) & ~df_full.modif_add.str.startswith(element)]\n",
    "    \n",
    "    # remove samples whose title shows the page is editor-oriented and not reader-oriented\n",
    "    for element in ['Discussion', 'Projet', 'Utilisateur', 'Wikipédia', 'Modèle', 'Catégorie']:\n",
    "        df_full = df_full[~df_full.title.str.startswith(element)]\n",
    "\n",
    "    # remove samples whose comments mention spelling or typing mistakes\n",
    "    for element in ['ortho', 'gramm', 'typo', 'frappe']:\n",
    "        df_full = df_full[~df_full.comment.str.lower().str.contains(element)]\n",
    "    \n",
    "    # remove samples whose comments mention reverting\n",
    "    for element in ['Annulation des modifications', 'Révocation des modifications']:\n",
    "        df_full = df_full[~df_full.comment.str.contains(element)]\n",
    "    \n",
    "    # remove sample with minor binary set as true\n",
    "    df_full = df_full[~df_full.minor]\n",
    "    \n",
    "    # remove samples whose username suggests the editor is a bot\n",
    "    df_full = df_full[~df_full.username.str.lower().str.contains(\"bot\") & ~df_full.comment.str.lower().str.contains(\"bot \")]\n",
    "    \n",
    "    # remove samples where modifications concern formatting (hyperlinks, functions, section title, \n",
    "    # bullet list, box, numbered list, references, math formulas, figures, tables, files)\n",
    "    for s in ['[', ']', '{', '}', '==', '===', '====', '=====', '*', '|', ';', '#', '!', ':', '<']: #,'•'\n",
    "        df_full = df_full[~df_full.modif_remove.str.startswith(s) & ~df_full.modif_add.str.startswith(s)]\n",
    "   \n",
    "    for s in ['<ref', 'ref>', '<math>', '</math>', 'Fichier:', 'Image:', '\\n\\\\|', '<br', 'br>', 'refnec']: #,'<sup', 'sup>', '<sub', 'sub>']:  ,\n",
    "        df_full = df_full[~df_full.modif_remove.str.contains(s) & ~df_full.modif_add.str.contains(s)]\n",
    "    \n",
    "    print('Shape after filtering: {0:,} rows | {1:,} columns'.format(df_full.shape[0], df_full.shape[1]))\n",
    "    ##### END FILTERS\n",
    "    \n",
    "    if init:\n",
    "        df_sample = df_full.sample(n=n_user, random_state=random_nbr)\n",
    "        df_sample = df_sample.fillna('')\n",
    "        \n",
    "    else:\n",
    "        df_sample_part = df_full.sample(n=n_user, random_state=random_nbr)\n",
    "        df_sample_part = df_sample_part.fillna('')\n",
    "        df_sample = pd.concat([df_sample, df_sample_part], ignore_index=True)\n",
    "        \n",
    "    init = False\n",
    "    del df_full\n",
    "    \n",
    "    t2 = time()-t1\n",
    "    m, s = divmod(t2, 60)\n",
    "    print('Round runtime: %d:%02d' % (m, s))\n",
    "\n",
    "df_sample.shape\n",
    "\n",
    "i=0\n",
    "\n",
    "# create sample_id\n",
    "for row in range(0, len(df_sample)):\n",
    "    df_sample.loc[row,'sample_id'] = df_sample.loc[row,'id_file'] + '_' + str(df_sample.loc[row,'id_modif'])\n",
    "    i+=1\n",
    "print(i)\n",
    "\n",
    "df_sample = df_sample[['sample_id', 'id_file', 'id_modif', 'label_incoherence', 'username', 'user_id',\n",
    "       'registered', 'format', 'model', 'id', 'parentid', 'title', 'minor',\n",
    "       'comment', 'modif', 'modif_remove', 'modif_add', 'timestamp',\n",
    "       'filt_bot', 'filt_coher', 'filt_confli', 'filt_contradic',\n",
    "       'filt_erreur', 'filt_erron', 'filt_faux', 'filt_frappe', 'filt_gramma',\n",
    "       'filt_ortho', 'filt_revert', 'filt_sens', 'filt_tromp', 'filt_typo',\n",
    "       'filt_vandalisme', 'filt_vraise']]\n",
    "\n",
    "duration = time() - t0\n",
    "m, s = divmod(duration, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(\"Running time: %d:%02d:%02d\" % (h, m, s), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save samples in a special format for human-made annotation tasks\n",
    "pre_annot_file = '35_39_73_pre_annot.csv'\n",
    "df_sample.to_csv('/media/hdd/salaun/wikiedit/annotations/data_v1/'+ pre_annot_file, sep=';')\n",
    "\n",
    "# save samples as df for classification experiments\n",
    "sample_tsv_file = '35_39_73_sample.tsv'\n",
    "df_sample.to_csv('/media/hdd/salaun/wikiedit/annotations/data_v1/'+ sample_tsv_file, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
